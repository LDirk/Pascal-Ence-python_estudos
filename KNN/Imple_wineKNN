# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V3KDLitL2X8x6WF2xqWEUoif7y9VyOCU
"""

from sklearn import datasets
import pandas as pd
import matplotlib.pyplot as plt

wine = datasets.load_wine()

df_wine = pd.DataFrame(data=wine.data,columns=wine.feature_names)

df_wine['class'] = wine.target # Criando coluna com os valores da variavel target

print(df_wine.head().T)
# Ver os 5 primeiros ( T transposta)

df_wine.info()

#Quantidade de amostras por classes 
df_wine["class"].value_counts()



#Separando os dados de treino e teste
from sklearn.model_selection import train_test_split

"""---"""

X_train, X_test, y_train, y_test = train_test_split(df_wine.drop('class',axis=1), df_wine['class'], test_size=0.3)
#teste 30%

#n_neighbors: Número de vizinhos (default = 5), é o parâmetro K que vimos na parte de funcionamento do algoritmo.
from sklearn.neighbors import KNeighborsClassifier

#Definindo o numero de vizinhos
knn = KNeighborsClassifier(n_neighbors=3)

# Agora iremos aplicar nossos dados de treino ao algoritmo KNN.

knn.fit(X_train, y_train)

# Executando o KNN com o conjunto de teste
resultado = knn.predict(X_test)
resultado

#Analisando e validando os resultados obtidos
#matriz de confusão

print (pd.crosstab(y_test,resultado, rownames=['Real'], colnames=['Predito'], margins=True))

from sklearn import metrics
print(metrics.classification_report(y_test,resultado,target_names=wine.target_names))

#Otimizando o parÂmetro k utilizando o GridSearch
from sklearn.model_selection import GridSearchCV

k_list = list(range(10,50))

# Colocamos os valores em um dicionário
parametros = dict(n_neighbors=k_list)

grid = GridSearchCV(knn, parametros, cv=5, scoring='accuracy')
#Instanciando o grid

#TREINANDO o objeto

grid.fit(df_wine.drop('class',axis=1),df_wine['class'])

print("Melhores parametros {} com o valor de acurácia {} ".format(grid.best_params_,grid.best_score_))




